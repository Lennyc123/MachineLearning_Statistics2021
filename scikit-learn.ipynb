{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9e13f84",
   "metadata": {},
   "source": [
    "# Machine Learning with Scikit-learn\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a50fea6d",
   "metadata": {},
   "source": [
    "The core aim of the following notebook is to utilise scikit-learn as a means to showcase working examples of the supervised machine learning tasks of **classification** and **regression**. Within the opening section of this notebook, an explanation of what the domain of machine learning consists of will take place. Following from this an overview of the the scikit-learn python library will be provided.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7309074",
   "metadata": {},
   "source": [
    "### Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4c087e4",
   "metadata": {},
   "source": [
    "Machine learning is regarded as a set of methods that contain the capacity to detect patterns in data and these methods then utilise such patterns to make future predictions (Garreta & Moncecchi, 2013; Hackeling, 2017; Jolly, 2018). Examples of machine learning in practice are that of predicting the weather, house prices, or detecting whether an email is spam or not. This notebook will place its emphasis on the machine learning category of supervised learning. Supervised learning is implemented when the data that we are analysing contains labels or a target variable that is numeric."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12821298",
   "metadata": {},
   "source": [
    "# An overview of the scikit-learn Python library"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "189a6f3d",
   "metadata": {},
   "source": [
    "Scikit-learn is regarded as a simple and efficient tool that one can utilise for predictive data analysis (Scikit-learn, 2022). The software is built entirely using Python and utilises some of the most popular libraries that Python has to offer, namely NumPy and SciPy (Jolly, 2018). It is a free and open-source software with algorithms embedded that assist one with the execution of supervised and unsupervised machine learning problems (Jolly, 2018). Scikit-learn can execute the following tasks: classification, regression, dimensionality reduction, and clustering. It also has modules for pre-processing data, extracting features, optimizing hyperparameters, and evaluating models (Hackeling, 2017)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1d7748",
   "metadata": {},
   "source": [
    "### Scikit-learn Common Procedures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95dfbbba",
   "metadata": {},
   "source": [
    "**When conducting supervised learning tasks the following steps are generally implemented.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccb78b9",
   "metadata": {},
   "source": [
    "- Read in the dataset\n",
    "    - *Exploratory data analysis (EDA)*\n",
    "    - *pre-process the data (Ensure that the dataset matches the **requirements** of scikit-learn)*\n",
    "- Import the required libraries and modules\n",
    "- Instantiate the algorithm\n",
    "- Split the data into training and test sets\n",
    "    - *Fit the model on the training set*\n",
    "    - *Predict on the test set*\n",
    "- Evaluate the performance of the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5858f5d",
   "metadata": {},
   "source": [
    "# Supervised Learning: Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02817c04",
   "metadata": {},
   "source": [
    "Regression is the prediction of the values of one more or **continous** response variables from one or more features (Hackeling, 2017). An example of this being that of predicting the length of a salmon as a function of its age and weight."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b9fbb3",
   "metadata": {},
   "source": [
    "### Importing the required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9cb60694",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For ease of legibility not all modules will be imported here\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing our dataset for regression\n",
    "from sklearn.datasets import load_diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75627d2f",
   "metadata": {},
   "source": [
    "### Parameters for enhancing the legibility of data visualisation i.e., graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a69d6004",
   "metadata": {},
   "outputs": [],
   "source": [
    "size=20\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (20,5),\n",
    "          'axes.labelsize': size,\n",
    "          'axes.titlesize': size,\n",
    "          'xtick.labelsize': size*0.75,\n",
    "          'ytick.labelsize': size*0.75,\n",
    "          'axes.titlepad': 15}\n",
    "plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d8b4ab9",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a22cc96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in the diabetes dataset as a pandas dataframe\n",
    "#Scikit-learn has some datasets that are embedded within\n",
    "data_d = load_diabetes(as_frame = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86374e61",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431e0ae",
   "metadata": {},
   "source": [
    "We can get an overview of the dataset by using the **'DESCR'** command, this informs us of the number of variables measured within the dataset i.e., the rows and columns within our pandas dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e887bc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data_d['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1780e8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Viewing the initial 5 rows of data\n",
    "#As stated within the description, all columns bar the target variable are numeric predictive values\n",
    "data_d.frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb35394d",
   "metadata": {},
   "source": [
    "### Dataset correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd9f032",
   "metadata": {},
   "source": [
    "Using a heatmap we can map out the relationship between each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918e32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "diabetes_correlation = data_d.frame.corr(method='pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c4d7f9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(diabetes_correlation, xticklabels=diabetes_correlation.columns, yticklabels=diabetes_correlation.columns, cmap='RdBu_r', annot=True, linewidth=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e67765f7",
   "metadata": {},
   "source": [
    "**The heatmap has informed us of the following:**\n",
    "- There is a strong positive correlation between s1(T-Cells) & s2(low-density lipoproteins)\n",
    "\n",
    "With reference to ones diabetes progression (*the target variable*):\n",
    "- A positive correlation was observed for the variables of **bmi** (body mass index) & **s5**(lamotrigine)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb79e9e0",
   "metadata": {},
   "source": [
    "### Depicting the observed correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ff61e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='s1', y='s2', data=data_d.frame, line_kws={'color':'red'})\n",
    "#axis labels\n",
    "plt.xlabel('T-Cells')\n",
    "plt.ylabel('low-density lipoproteins')\n",
    "plt.title('Correlation between T-Cells & low-density lipoproteins');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0396eb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='bmi', y='target', data=data_d.frame, line_kws={'color':'red'})\n",
    "#axis labels\n",
    "plt.xlabel('bmi')\n",
    "plt.ylabel('disease progression')\n",
    "plt.title('Correlation between bmi & disease progression');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b97e3e58",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(x='s5', y='target', data=data_d.frame, line_kws={'color':'red'});\n",
    "#axis labels\n",
    "plt.xlabel('lamotrigine')\n",
    "plt.ylabel('disease progression')\n",
    "plt.title('Correlation between lamotrigine & disease progression');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6321804",
   "metadata": {},
   "source": [
    "## Linear regression in two dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784e1bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the feature and target variables\n",
    "feature = data_d.frame['bmi'].values\n",
    "target = data_d.frame['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3998f5c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plotting the values of the feature and target variabels i.e., bmi and disease progression\n",
    "plt.scatter(feature, target)\n",
    "#axis labels\n",
    "plt.xlabel('bmi')\n",
    "plt.ylabel('disease progression')\n",
    "plt.title('bmi Vs. disease progression');\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5a3c22",
   "metadata": {},
   "source": [
    "### Utilising scikit-learn in order to conduct linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8bd12d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required the required module\n",
    "from sklearn import linear_model\n",
    "\n",
    "#Initialising a linear regression model\n",
    "linear_reg = linear_model.LinearRegression()\n",
    "\n",
    "#Reshaping the array since we only have a single feature\n",
    "feature = feature.reshape(-1,1)\n",
    "target = target.reshape(-1,1)\n",
    "\n",
    "#fitting the model on the data\n",
    "linear_reg.fit(feature, target)\n",
    "\n",
    "#Define the limits of the x axis\n",
    "x_lim = np.linspace(min(feature), max(feature)).reshape(-1,1)\n",
    "\n",
    "#Scatter plot\n",
    "plt.scatter(feature, target)\n",
    "\n",
    "#Prediction line\n",
    "plt.plot(x_lim, linear_reg.predict(x_lim), color='red')\n",
    "\n",
    "#axis labels\n",
    "plt.xlabel('bmi')\n",
    "plt.ylabel('disease progression')\n",
    "plt.title('bmi Vs. disease progression')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b5f749",
   "metadata": {},
   "source": [
    "## Linear regression to predict the progression of diabetes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1068ac97",
   "metadata": {},
   "source": [
    "### Predicting disease progression while taking into consideration all measured variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8146d55e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the features and target variables\n",
    "# the features variable contains all measured variables bar disease progression i.e., the target variable\n",
    "features = data_d.frame.drop('target', axis=1)\n",
    "target = data_d.frame['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc00dba",
   "metadata": {},
   "source": [
    "#### Splitting our dataset into training and test sets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d65a23",
   "metadata": {},
   "source": [
    "70% of the data is used for training the model, while 30% is used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9c55575",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing the required module\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04857f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing a linear regression model\n",
    "linear_reg = linear_model.LinearRegression()\n",
    "\n",
    "#Fitting the model on the data\n",
    "L_reg = linear_reg.fit(X_train, y_train)\n",
    "\n",
    "# predictions\n",
    "y_test_pred = L_reg.predict(X_test)\n",
    "\n",
    "#Accuracy of the model\n",
    "linear_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b90b6dc",
   "metadata": {},
   "source": [
    "### Plotting the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816e1a6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(y_test, y_test_pred)\n",
    "plt.plot(y_test, y_test, color='red');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ef86f87",
   "metadata": {},
   "source": [
    "## Model optimisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea66216f",
   "metadata": {},
   "source": [
    "### Ridge regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bbac958",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing required module\n",
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Reading in the dataset \n",
    "#data_d = load_diabetes(as_frame = True)\n",
    "\n",
    "# Creating the features and target variables\n",
    "features = data_d.frame.drop('target', axis=1)\n",
    "target = data_d.frame['target'].values\n",
    "\n",
    "#Splitting our dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)\n",
    "\n",
    "#Initialize a ridge regression model\n",
    "ridge_reg = Ridge(alpha = 0, normalize = True)\n",
    "\n",
    "#Fit the model to the training data \n",
    "ridge_reg.fit(X_train, y_train)\n",
    "\n",
    "#Extract the score from the test data\n",
    "ridge_reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0cc0f8",
   "metadata": {},
   "source": [
    "Our attempt to penalise hyper-optimised coefficients did not provide fruitful as no improvement in the accurary score of our model occured."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e566ad",
   "metadata": {},
   "source": [
    "### Optimizing alpha using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1219de7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Importing required module\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "#Building the model  \n",
    "ridge_regression = Ridge()\n",
    "\n",
    "#Using GridSearchCV to search for the best parameter\n",
    "grid = GridSearchCV(ridge_regression, {'alpha':[0.0001, 0.001, 0.01, 0.1, 10]})\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print out the best parameter\n",
    "print(\"The most optimal value of alpha is:\", grid.best_params_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e34feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an ridge regression object\n",
    "ridge_regression = Ridge(alpha = 0.001)\n",
    "\n",
    "#Fitting the model to the training and test sets\n",
    "ridge_regression.fit(X_train, y_train)\n",
    "\n",
    "#Accuracy score of the ridge regression model\n",
    "ridge_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c63a88",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Store train/test errors within an a list\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "#List with varying alpha values\n",
    "alpha_list = [0.0001, 0.001, 0.01, 0.1, 10]\n",
    "\n",
    "# Evaluate the training and test classification errors for each value of alpha\n",
    "for value in alpha_list:\n",
    "    \n",
    "    # Create Ridge object and fit\n",
    "    ridge_regression = Ridge(alpha= value)\n",
    "    ridge_regression.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate error rates and append to lists\n",
    "    train_errors.append(ridge_regression.score(X_train, y_train) )\n",
    "    test_errors.append(ridge_regression.score(X_test, y_test))\n",
    "    \n",
    "# Plot results\n",
    "plt.semilogx(alpha_list, train_errors, alpha_list, test_errors)\n",
    "plt.legend((\"train\", \"test\"))\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.xlabel('Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77405d15",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df92b7f2",
   "metadata": {},
   "source": [
    "# Supervised Learning: Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbe25a66",
   "metadata": {},
   "source": [
    "Classification is the prediction of **discrete** values for one or more response variables from one or more features (Hackeling, 2017). An example of this being that of classifying houses into expensive or affordable categories based on their price, area, bedrooms etc.,"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24156ff",
   "metadata": {},
   "source": [
    "### Importing the required libraries and modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "75647e0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# import pandas as pd\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "#Importing our dataset for classification\n",
    "from sklearn.datasets import load_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f4123d",
   "metadata": {},
   "source": [
    "### Parameters for enhancing the legibility of data visualisation i.e., graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6af7451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# size=20\n",
    "# params = {'legend.fontsize': 'large',\n",
    "#           'figure.figsize': (20,5),\n",
    "#           'axes.labelsize': size,\n",
    "#           'axes.titlesize': size,\n",
    "#           'xtick.labelsize': size*0.75,\n",
    "#           'ytick.labelsize': size*0.75,\n",
    "#           'axes.titlepad': 15}\n",
    "# plt.rcParams.update(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1e35c63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Return to default seaborn theme\n",
    "# sns.set_theme()\n",
    "\n",
    "#Setting the style of the seaborn graphs\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_palette(\"Set1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7376f5c",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b80c48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading in our dataset as a pandas dataframe\n",
    "data = load_wine(as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02f8a62",
   "metadata": {},
   "source": [
    "### Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fcbfc6",
   "metadata": {},
   "source": [
    "We can get an overview of the dataset by using the **'DESCR'** command, this informs us of the number of variables measured within the dataset i.e., the rows and columns within our pandas dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c03463f",
   "metadata": {},
   "source": [
    "The data is the results of a chemical analysis of wines grown in the same region in Italy by three different cultivators. There are thirteen different measurements taken for different constituents found in the three types of wine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75eb51a3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(data['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6b6b8e",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Viewing the initial 5 rows of data\n",
    "data.frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "164b6132",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa43a7d",
   "metadata": {},
   "source": [
    "### A Brief overview regarding the target variable of the different types of wine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc337fdd",
   "metadata": {},
   "source": [
    "#### How the names of the different wines are defined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a9b877",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "category = data.target_names\n",
    "for i in category:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "492df2b8",
   "metadata": {},
   "source": [
    "#### The number of instances of each type of wine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9802de9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_category_count = data.frame['target'].value_counts()\n",
    "wine_category_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017d591d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "frequency_map = sns.countplot(y=\"target\",\n",
    "                              order = data.frame[\"target\"].value_counts(ascending=True).index, \n",
    "                              hue=\"target\", \n",
    "                              dodge=False, \n",
    "                              data=data.frame,\n",
    "                             )\n",
    "\n",
    "frequency_map.set(title=\"Number of instances within each wine category\", \n",
    "                         xlabel = \"Frequency\", \n",
    "                         ylabel = \"Wine Category\")\n",
    "\n",
    "plt.legend([\"Wine Type 0\",\"Wine Type 1\", \"Wine Type 2\"],title = \"Categories\")\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bef22d4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Please note this command may take a minute to execute due to the number of variables within the dataset.\n",
    "\n",
    "# sns.pairplot(data.frame, hue='target', palette=\"Set1\")\n",
    "# plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7daf319",
   "metadata": {},
   "source": [
    "### The average of each variable sorted by wine type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fd0fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_category_sort = data.frame.groupby(\"target\")\n",
    "wine_category_sort.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfea1cf6",
   "metadata": {},
   "source": [
    "The pairplot & the average table plotted above inform us that the variables of **alcohol**, **flavanoids**, **color intensity** and **proline** are most informative regarding how we could potientially distinguish between the different types of wine. It may be suggested that we can propose what category a wine belongs to based on these variables. As each type of wine may have a distinct amount of each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "327457b1",
   "metadata": {},
   "source": [
    "### Kernel density estimate plots of the four key variables specified above (*alcohol, flavanoids, color intensity & proline*)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8631d149",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.displot(data=data.frame, x=data.frame['alcohol'], hue=\"target\", kind='kde', fill=True, palette=\"Set1\");\n",
    "\n",
    "sns.displot(data=data.frame, x=data.frame['flavanoids'], hue=\"target\", kind='kde', fill=True, palette=\"Set1\");\n",
    "\n",
    "sns.displot(data=data.frame, x=data.frame['color_intensity'], hue=\"target\", kind='kde', fill=True, palette=\"Set1\");\n",
    "\n",
    "sns.displot(data=data.frame, x=data.frame['proline'], hue=\"target\", kind='kde', fill=True, palette=\"Set1\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3215da4b",
   "metadata": {},
   "source": [
    "#### Average table of these four variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c403b9f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_table = data.frame[['alcohol', 'flavanoids', 'color_intensity',  'proline','target']]\n",
    "info_table\n",
    "\n",
    "sub_info = info_table.groupby('target')\n",
    "sub_info.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a458f71",
   "metadata": {},
   "source": [
    "### Dataset Correlation "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65743519",
   "metadata": {},
   "source": [
    "Using a heatmap we can map out the relationship between each of the variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06b96e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation = data.data.corr(method = 'pearson')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd467c2",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.heatmap(correlation, xticklabels=correlation.columns, yticklabels=correlation.columns, cmap='RdBu_r', annot=True, linewidth=0.5);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee249306",
   "metadata": {},
   "source": [
    "# Predicting Categories using the K-Nearest Neighbors algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7153377f",
   "metadata": {},
   "source": [
    "### Splitting the data into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "37a259fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the features and target variables\n",
    "features = data.frame.drop('target', axis =1).values\n",
    "target = data.frame['target'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf9d1a39",
   "metadata": {},
   "source": [
    "70% of the data is used for training the model, while 30% is used for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ddda88de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required module\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, stratify=target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24c256c",
   "metadata": {},
   "source": [
    "### Implementation and evaluation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "abeab30a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6851851851851852"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import k-nearest neighbors Classifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Initialising the KNN classifier with 3 neighbors\n",
    "# The number of neighbors is chosen arbitrarily\n",
    "knn_classifier = KNeighborsClassifier(n_neighbors=3)\n",
    "\n",
    "# Fitting the classifier on the training data\n",
    "knn_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Extracting the accuracy score from the test sets\n",
    "knn_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ec42e4",
   "metadata": {},
   "source": [
    "## Fine-tuning the parameters of the K-NN algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b981e0b3",
   "metadata": {},
   "source": [
    "### Using GridSearchCV (algorithm) to find the optimal number of neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1e54e138",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8608bfc4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, estimator=KNeighborsClassifier(),\n",
       "             param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initializing a grid with possible number of neighbors from 1 to 24\n",
    "grid = {'n_neighbors' : np.arange(1, 25)}\n",
    "\n",
    "#Initializing a k-NN classifier \n",
    "knn_classifier = KNeighborsClassifier()\n",
    "\n",
    "#Using cross validation to find optimal number of neighbors \n",
    "knn = GridSearchCV(knn_classifier, grid, cv = 10)\n",
    "\n",
    "# Fitting the classifier on the training data\n",
    "knn.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e4bc9d15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_neighbors': 23}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the optimal number of neighbors \n",
    "knn.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c91e630",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7397435897435898"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Extracting the accuracy score for optimal number of neighbors\n",
    "knn.best_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0dab624",
   "metadata": {},
   "source": [
    "### Scaling for optimized performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2127c59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a43e07a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9814814814814815"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting up the scaling pipeline\n",
    "pipeline_order = [('scaler', StandardScaler()),\n",
    "                  ('knn', KNeighborsClassifier(n_neighbors = 23))]\n",
    "\n",
    "pipeline = Pipeline(pipeline_order)\n",
    "\n",
    "#Fitting the classifier to the scaled dataset\n",
    "knn_classifier_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Extracting the score\n",
    "knn_classifier_scaled.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54d9fa3f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ed953b",
   "metadata": {},
   "source": [
    "**Our attempts to further optimize the performance of the model proved fruitful**\n",
    "- Our initial accuracy score of **0.685** was increase to that of **0.739** through the process of finding the models *optimal number of neighbors* for this particular dataset.\n",
    "- Through the process of establishing a *pipeline and scaling the data* the accuracy score of **0.739** increased to **0.981**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf382ae2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794fc443",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24445ba2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d651e",
   "metadata": {},
   "source": [
    "Garreta, R. and Moncecchi, G. (2013) Learning Scikit-learn : Machine Learning in Python: Experience the Benefits of Machine Learning Techniques by Applying Them to Real-world Problems Using Python and the Open Source Scikit-learn Library. Birmingham, UK: Packt Publishing (Community Experience Distilled). Available at: https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=e000xww&AN=673033&site=ehost-live&scope=site (Accessed: 26 July 2022).\n",
    "\n",
    "Hackeling, G. (2017) Mastering Machine Learning with Scikit-learn - Second Edition. Birmingham, UK: Packt Publishing. Available at: https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=e000xww&AN=1562686&site=ehost-live&scope=site (Accessed: 26 July 2022).\n",
    "\n",
    "Kevin Jolly (2018) Machine Learning with Scikit-learn Quick Start Guide : Classification, Regression, and Clustering Techniques in Python. Birmingham, UK: Packt Publishing. Available at: https://search.ebscohost.com/login.aspx?direct=true&AuthType=ip,sso&db=e000xww&AN=1936459&site=ehost-live&scope=site (Accessed: 23 July 2022).\n",
    "\n",
    "Scikit-learn (2022), Getting started, Available at: https://scikit-learn.org/stable/getting_started.html (Accessed: 26 July 2022).  \n",
    "Scikit-learn (2022), User guide, Available at: https://scikit-learn.org/stable/user_guide.html (Accessed: 26 July 2022).  \n",
    "Scikit-learn (2022), tutorial, Available at: https://scikit-learn.org/stable/tutorial/index.html (Accessed: 26 July 2022)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
